# -*- coding: utf-8 -*-
"""stats-project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14EtHgsIQWRAJAXj_rokDDQghOXqmCB6D
"""

# Import required libraries
import numpy as np
import matplotlib.pyplot as plt

# Given data
data = np.array([4, 6, 5, 7, 6, 8, 5, 6, 7, 6, 5, 9])
n = len(data)

# -----------------------------
# Frequency table
values, frequencies = np.unique(data, return_counts=True)
cumulative_freq = np.cumsum(frequencies)

# -----------------------------
# 1. Histogram
plt.figure(figsize=(8,5))
plt.hist(data, bins=range(min(data), max(data)+2), color='skyblue', edgecolor='black', rwidth=0.8)
plt.title("Histogram")
plt.xlabel("Data Values")
plt.ylabel("Frequency")
plt.xticks(range(min(data), max(data)+1))
plt.grid(True)
plt.show()

# -----------------------------
# 2. Frequency Polygon
plt.figure(figsize=(8,5))
plt.plot(values, frequencies, marker='o', color='red', linewidth=2)
plt.title("Frequency Polygon")
plt.xlabel("Data Values")
plt.ylabel("Frequency")
plt.xticks(range(min(data), max(data)+1))
plt.grid(True)
plt.show()

# -----------------------------
# 3. Ogive (Cumulative Frequency Curve)
plt.figure(figsize=(8,5))
plt.plot(values, cumulative_freq, marker='o', color='green', linewidth=2)
plt.title("Ogive (Cumulative Frequency Curve)")
plt.xlabel("Data Values")
plt.ylabel("Cumulative Frequency")
plt.xticks(range(min(data), max(data)+1))
plt.grid(True)
plt.show()

# ------------------------------------
# Classical Probability Examples
# ------------------------------------

# 1. Complementary Rule
# P(A') = 1 - P(A)

P_A = 0.35
P_A_complement = 1 - P_A

print("Complementary Rule:")
print("P(A) =", P_A)
print("P(A') =", P_A_complement)
print()

# ------------------------------------
# 2. Empirical Probability
# Empirical Probability = Number of favorable outcomes / Total outcomes

favorable = 18
total = 50

empirical_probability = favorable / total

print("Empirical Probability:")
print("Probability =", empirical_probability)
print()

# ------------------------------------
# 3. Subjective Probability
# Based on personal judgment or experience

subjective_probability = 0.6

print("Subjective Probability:")
print("Probability =", subjective_probability)
print()

# ------------------------------------
# 4. Additive Probability Rule
# P(A or B) = P(A) + P(B) - P(A and B)

P_A = 0.4
P_B = 0.5
P_A_and_B = 0.2

P_A_or_B = P_A + P_B - P_A_and_B

print("Additive Probability Rule:")
print("P(A or B) =", P_A_or_B)
print()

# ------------------------------------
# 5. Multiplicative Probability Rule
# P(A and B) = P(A) × P(B)
# (For independent events)

P_A = 0.3
P_B = 0.6

P_A_and_B = P_A * P_B

print("Multiplicative Probability Rule:")
print("P(A and B) =", P_A_and_B)
print()

# ------------------------------------
# 6. Conditional Probability
# P(A | B) = P(A and B) / P(B)

P_A_and_B = 0.15
P_B = 0.5

conditional_probability = P_A_and_B / P_B

print("Conditional Probability:")
print("P(A | B) =", conditional_probability)

# ------------------------------------
# Bayes' Theorem
# ------------------------------------
# Formula:
# P(A | B) = [P(B | A) × P(A)] / P(B)

# Given probabilities
P_A = 0.3          # Probability of event A
P_not_A = 0.7      # Probability of not A

P_B_given_A = 0.8      # Probability of B given A
P_B_given_not_A = 0.2  # Probability of B given not A

# Total probability of B
# P(B) = P(B|A)P(A) + P(B|A')P(A')
P_B = (P_B_given_A * P_A) + (P_B_given_not_A * P_not_A)

# Bayes' Theorem
P_A_given_B = (P_B_given_A * P_A) / P_B

print("Bayes' Theorem:")
print("P(A | B) =", P_A_given_B)

# ------------------------------------
# Binomial Distribution
# ------------------------------------

# Given values
n = 5      # number of trials
x = 2      # number of successes
p = 0.4    # probability of success
q = 1 - p  # probability of failure

# -----------------------------
# Factorial function
def factorial(num):
    result = 1
    for i in range(1, num + 1):
        result *= i
    return result

# -----------------------------
# Combination function
# nCx = n! / (x! (n-x)!)
def combination(n, x):
    return factorial(n) / (factorial(x) * factorial(n - x))

# -----------------------------
# Binomial Probability Formula
binomial_probability = combination(n, x) * (p ** x) * (q ** (n - x))

print("Binomial Distribution:")
print("P(X =", x, ") =", binomial_probability)

# ------------------------------------
# Poisson Distribution
# ------------------------------------
import math

# Given values
lam = 3      # average number of events (lambda)
x = 2        # number of occurrences

# Poisson probability formula
poisson_probability = (math.exp(-lam) * (lam ** x)) / math.factorial(x)

print("Poisson Distribution:")
print("P(X =", x, ") =", poisson_probability)

# ------------------------------------
# Normal Distribution
# ------------------------------------
import numpy as np
import matplotlib.pyplot as plt

# Given values
mu = 50        # mean
sigma = 5      # standard deviation
X = 55         # value to find probability density

# -----------------------------
# Normal Distribution formula
normal_prob = (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-((X - mu)**2) / (2 * sigma**2))
print("Normal Distribution:")
print("P(X =", X, ") =", normal_prob)

# -----------------------------
# Plot Normal Distribution curve
x_values = np.linspace(mu - 4*sigma, mu + 4*sigma, 100)
y_values = (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-((x_values - mu)**2) / (2 * sigma**2))

plt.plot(x_values, y_values, color='blue')
plt.title("Normal Distribution Curve")
plt.xlabel("X")
plt.ylabel("Probability Density")
plt.grid(True)
plt.show()

import numpy as np

# -----------------------------
# Population Data (Example)
population = np.array([10, 12, 15, 18, 20, 22, 25, 28, 30, 35])
n = len(population)
print("Population:", population)

# -----------------------------
# 1. Simple Random Sampling
sample_size = 4
simple_random_sample = np.random.choice(population, size=sample_size, replace=False)
print("\nSimple Random Sample:", simple_random_sample)

# -----------------------------
# 2. Systematic Sampling
k = 2  # select every kth element
systematic_sample = population[::k]
print("\nSystematic Sample:", systematic_sample)

# -----------------------------
# 3. Stratified Sampling
# Suppose population is divided into 2 strata
stratum1 = np.array([10, 12, 15, 18, 20])  # stratum 1
stratum2 = np.array([22, 25, 28, 30, 35])  # stratum 2

# Sample 2 from each stratum
sample_stratum1 = np.random.choice(stratum1, size=2, replace=False)
sample_stratum2 = np.random.choice(stratum2, size=2, replace=False)
stratified_sample = np.concatenate([sample_stratum1, sample_stratum2])
print("\nStratified Sample:", stratified_sample)

import numpy as np
import scipy.stats as stats

# -----------------------------
# Sample Data
data = np.array([12, 15, 14, 16, 13, 15, 14, 16, 15, 14])
n = len(data)
print("Sample Data:", data)

# -----------------------------
# 1. Point Estimation
# Point estimate of mean
sample_mean = np.mean(data)
# Point estimate of standard deviation
sample_std = np.std(data, ddof=1)  # sample standard deviation
print("\nPoint Estimation:")
print("Sample Mean =", sample_mean)
print("Sample Standard Deviation =", sample_std)

# -----------------------------
# 2. Interval Estimation (Confidence Interval)
confidence_level = 0.95
alpha = 1 - confidence_level
# t-critical value for 95% confidence
t_critical = stats.t.ppf(1 - alpha/2, df=n-1)

# Margin of Error
margin_error = t_critical * (sample_std / np.sqrt(n))

# Confidence Interval
CI_lower = sample_mean - margin_error
CI_upper = sample_mean + margin_error

print("\nInterval Estimation (95% Confidence Interval):")
print("Lower Limit =", CI_lower)
print("Upper Limit =", CI_upper)

import numpy as np
from scipy import stats

# -----------------------------
# Sample Data
data = np.array([12, 15, 14, 16, 13, 15, 14, 16, 15, 14])
n = len(data)
sample_mean = np.mean(data)
sample_std = np.std(data, ddof=1)  # sample standard deviation

# -----------------------------
# 1. Z-Test (if population std is known)
# Suppose population mean (mu) = 14, population std (sigma) = 1.5
mu = 14
sigma = 1.5

z_stat = (sample_mean - mu) / (sigma / np.sqrt(n))
# Two-tailed p-value
p_value_z = 2 * (1 - stats.norm.cdf(abs(z_stat)))

print("Z-Test:")
print("Z-Statistic =", z_stat)
print("P-Value =", p_value_z)

# -----------------------------
# 2. T-Test (if population std unknown)
# Null Hypothesis H0: mean = 14
t_stat, p_value_t = stats.ttest_1samp(data, popmean=14)

print("\nT-Test:")
print("T-Statistic =", t_stat)
print("P-Value =", p_value_t)

# -----------------------------
# Interpretation
alpha = 0.05
if p_value_t < alpha:
    print("\nReject Null Hypothesis (significant difference)")
else:
    print("\nFail to Reject Null Hypothesis (no significant difference)")

import numpy as np
from scipy import stats

# -----------------------------
# Sample Data
data = np.array([12, 15, 14, 16, 13, 15, 14, 16, 15, 14])
n = len(data)
sample_mean = np.mean(data)
sample_std = np.std(data, ddof=1)  # sample standard deviation

# -----------------------------
# 1. One-Tailed Z-Test (Right-Tailed)
# Suppose population mean (mu) = 14, population std (sigma) = 1.5
mu = 14
sigma = 1.5

z_stat = (sample_mean - mu) / (sigma / np.sqrt(n))
# Right-tailed p-value
p_value_z = 1 - stats.norm.cdf(z_stat)

print("One-Tailed Z-Test (Right-Tailed):")
print("Z-Statistic =", z_stat)
print("P-Value =", p_value_z)

# -----------------------------
# 2. One-Tailed T-Test (Right-Tailed)
# Null Hypothesis H0: mean <= 14
t_stat, p_value_two_tailed = stats.ttest_1samp(data, popmean=14)
# Convert to one-tailed
if t_stat > 0:
    p_value_t = p_value_two_tailed / 2
else:
    p_value_t = 1 - (p_value_two_tailed / 2)

print("\nOne-Tailed T-Test (Right-Tailed):")
print("T-Statistic =", t_stat)
print("P-Value =", p_value_t)

# -----------------------------
# Interpretation
alpha = 0.05
if p_value_t < alpha:
    print("\nReject Null Hypothesis (mean > 14 is significant)")
else:
    print("\nFail to Reject Null Hypothesis (not significant)")

import numpy as np
from scipy import stats

# -----------------------------
# Sample Data
data = np.array([12, 15, 14, 16, 13, 15, 14, 16, 15, 14])
n = len(data)
sample_mean = np.mean(data)
sample_std = np.std(data, ddof=1)  # sample standard deviation

# -----------------------------
# 1. Two-Tailed Z-Test
# Suppose population mean (mu) = 14, population std (sigma) = 1.5
mu = 14
sigma = 1.5

z_stat = (sample_mean - mu) / (sigma / np.sqrt(n))
# Two-tailed p-value
p_value_z = 2 * (1 - stats.norm.cdf(abs(z_stat)))

print("Two-Tailed Z-Test:")
print("Z-Statistic =", z_stat)
print("P-Value =", p_value_z)

# -----------------------------
# 2. Two-Tailed T-Test
# Null Hypothesis H0: mean = 14
t_stat, p_value_t = stats.ttest_1samp(data, popmean=14)

print("\nTwo-Tailed T-Test:")
print("T-Statistic =", t_stat)
print("P-Value =", p_value_t)

# -----------------------------
# Interpretation
alpha = 0.05
if p_value_t < alpha:
    print("\nReject Null Hypothesis (significant difference from 14)")
else:
    print("\nFail to Reject Null Hypothesis (not significant)")

import numpy as np
import pandas as pd

# -----------------------------
# Given data
data = np.array([81, 66, 42, 73, 79, 27, 88, 66, 28, 70, 12, 71, 54, 77, 18,
                 56, 97, 47, 59, 18, 26, 69, 70, 39, 34, 32, 51, 35, 74, 56])
n = len(data)

# -----------------------------
# Define number of classes (Sturges' rule)
k = int(np.ceil(1 + 3.322 * np.log10(n)))

# Class width
class_width = int(np.ceil((max(data) - min(data)) / k))

# -----------------------------
# Create class intervals
lower_limit = min(data)
classes = []
for i in range(k):
    upper_limit = lower_limit + class_width - 1
    classes.append((lower_limit, upper_limit))
    lower_limit = upper_limit + 1

# -----------------------------
# Build frequency table as a list
table_rows = []
cumulative_freq = 0
for cl in classes:
    lower, upper = cl
    # Class boundaries
    boundary = (lower - 0.5, upper + 0.5)
    # Frequency
    freq = np.sum((data >= lower) & (data <= upper))
    cumulative_freq += freq
    # Tally marks
    tally = '|' * freq
    # Relative frequency
    rel_freq = freq / n
    # Percentage frequency
    perc_freq = rel_freq * 100
    # Append as dictionary
    table_rows.append({
        'Class Interval': f"{lower}-{upper}",
        'Class Boundary': f"{boundary[0]}-{boundary[1]}",
        'Tally': tally,
        'Frequency': freq,
        'Relative Frequency': round(rel_freq, 3),
        'Percentage Frequency': round(perc_freq, 2),
        'Cumulative Frequency': cumulative_freq
    })

# Convert list of dictionaries to DataFrame
freq_table = pd.DataFrame(table_rows)

# -----------------------------
# Display Frequency Distribution Table
print("Frequency Distribution Table:" )
print(freq_table)